{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f93fd216",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Optimisation\n",
    "A process concerned with finding the best available solution(s)\n",
    "\n",
    "Is, of course, everywhere (engineering, finance, decision-making, computer science, machine learning etc)\n",
    "\n",
    "<!-- Training models, hyperparameter tuning, and neural network optimization. -->\n",
    "\n",
    "We are almost always trying to optimise something e.g. maximise profit, maximise efficiency, minimise energy consumption\n",
    "\n",
    "<!-- (As a consultant engineer we spoke frequently about 'the triangle' with vertices of cost, time and quality. Inevitably to improve one you needed to detract from one or both of the others.) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd1945c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Generically:\n",
    "$$\n",
    "\\min_{x\\in \\mathbb{R}^n} f_i(x), \\quad (i=1,2,\\ldots, M)\n",
    "$$\n",
    "\n",
    "**The objective function**, $f_i(x)$:\n",
    "- is the cost for objective $i$, where there are $M$ is the number of objective functions\n",
    "- this is the function that needs to be maximized or minimised\n",
    "- if $M=1$ then this is a *'single objective'* optimisation, while $M>1$ is a *'multi-objective'* optimisation\n",
    "- if the objective function (and constraints) are linear then we speak of linear programming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca34d73",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$$\n",
    "\\color{white}{\\min_{x\\in \\mathbb{R}^n} f_i(x), \\quad (i=1,2,\\ldots, M)}\n",
    "$$\n",
    "\n",
    "**The design variables**, $x$: \n",
    "- $n$ input parameters to be 'guessed' by the optimisation algorithm\n",
    "- these are the factors that affect the outcome of the objective function\n",
    "- $\\mathbb{R}^n$ is the space spanned by the decision variables (the *'search space'*)\n",
    "- variables can be continuous or restricted to discrete values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3226856a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "$$\n",
    "\\color{white}{\\min_{x\\in \\mathbb{R}^n} f_i(x), \\quad (i=1,2,\\ldots, M)}\n",
    "$$\n",
    "\n",
    "**The constraints**:\n",
    "- there may be limitations or restrictions (such as equalities or inequalities) within which the optimisation must occur:\n",
    "$$\n",
    "\\color{white}{h_j(x)=0, \\quad (j=1,2, \\dots, J)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\color{white}{g_k(x) \\leq 0, \\quad (k=1,2,\\ldots, K)}\n",
    "$$\n",
    "\n",
    "- the set of all possible solutions that satisfy the constraints is the *feasible region* \n",
    "- if there are no constraints (e.g. $J=0$ and $K=0$) then this is an *'unconstrained'* problem and $x\\in \\mathbb{R}^n$ (while if $J>0$ or $K>0$ then it is a *'constrained'* problem)\n",
    "- if any of $f_i$, $h_j$ and $g_k$ are nonlinear then the problem is classified as a nonlinear optimisation problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c0b30d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Global vs. Local Optimisation:\n",
    "\n",
    "**Local Optimisation:** Finding the best solution within a specific, possibly limited region of the feasible space\n",
    "- local optima are solutions that are optimal within a neighboring set of solutions, but not necessarily across the entire space\n",
    "- less computationally intensive\n",
    "- gradient descent, Newton’s method, simplex method,...\n",
    "\n",
    "**Global Optimisation:** Finding the absolute best solution across the entire feasible region\n",
    "- often more complex and computationally intensive because the algorithm must explore the entire search space\n",
    "- particularly important for non-convex functions, which may have multiple local optima\n",
    "- simulated annealing, genetic algorithms, branch and bound, ..., **particle swarm optimisation** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a65ff1b",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Some categorisations...\n",
    "\n",
    "- Deterministic e.g. hill-climbing vs Stochastic e.g. particle swarm optimisation (PSO)\n",
    "\n",
    "- Single agent e.g. simulated annealing vs population-based e.g. PSO\n",
    " \n",
    "- (meta-)heuristics e.g. PSO vs bio/nature-inspired based on a successful system e.g. genetic algorithms\n",
    "    - *Heuristics* are rule-of-thumb or intuitive strategies used to quickly find good solutions to problems. They are typically designed for specific problem instances or problem types\n",
    "    - *Metaheuristics* are higher-level strategies that guide the search for solutions in a broader, more generic manner. They are not tied to specific problem structures and can be applied to a wide range of optimisation problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8cb612",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Swarm optimisation\n",
    "Swarm optimisation is an iterative process carried out by a collective of interacting individuals\n",
    "\n",
    "It continues until certain termination criteria are met, which could include a maximum number of iterations, a specific level of convergence, or a predetermined threshold for the fitness score\n",
    "\n",
    "We will cover the basics with respect to a particular swarm optimiser: particle swarm optimisation (PSO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd9c33f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Particle swarm optimisation (PSO)\n",
    "\n",
    "\n",
    "\n",
    "First intended for simulating social behaviour as a stylised representation of the movement of organisms in a bird flock or fish school\n",
    "\n",
    "Kennedy and Eberhart included a roost, or, more generally, an attraction point (e.g, a prey) in a simplified Boids-like simulation, such that each agent:\n",
    "- is attracted to the location of the roost\n",
    "- remembers where it was closer to the roost\n",
    "- shares information with its neighbors about its closest location to the roost\n",
    "\n",
    "Eventually (almost) all agents landed at the roost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a58b029",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "They then flipped the set up such that:\n",
    "- roost was an unknown extremum of a function\n",
    "- distance to the roost represented quality of current agent position on the optimisation landscape\n",
    "\n",
    "\n",
    "The PSO algorithm uses only basic mathematical operators and is computationally inexpensive in terms of both memory requirements and speed\n",
    "    *\"very simple concept, and paradigms can be implemented in a few lines of computer code.\" - Kennedy et al.*\n",
    "    \n",
    "It has undergone continued development since it was first proposed in 1995 and continues to be used today\n",
    "\n",
    "<!-- Kennedy J. and Eberhart R. C. Particle swarm optimization. In Proceedings of the International Conference on Neural Networks; Institute of Electrical and Electronics Engineers. Vol. 4. 1995. pp. 1942–1948. DOI: 10.1109/ICNN.1995.488968 -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce7a0c5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The search space \n",
    "The set of possible solutions is the search/solution space (this may be an abstract space, e.g. a position in it could represent a set of variables or parameters)\n",
    "\n",
    "Each particle (aka agent) has a state (its position) that represents a solution to the optimisation problem\n",
    "\n",
    "<!-- A solution point $x \\in X_n \\subseteq \\mathbb{R}^n $ for an optimisation problem with objective function $f(x): X_n \\mapsto \\mathbb{R}^m$ -->\n",
    "\n",
    "Agents move through the search space, adjusting their positions based on their own experience and the experience of neighbouring particles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520b8bcb",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Fitness function (aka objective function, cost function)\n",
    "\n",
    "The fitness function provides the means to objectively compare different candidate solutions and select the best ones for further exploration \n",
    "\n",
    "It is specific to *the particular problem* i.e. it is designed using domain knowledge and informs about how well a solution meets the objectives \n",
    "\n",
    "The *'fitness'* is then the output of the fitness function for a given potential solution, representing the quality of the agent's position on the optimisation landscape \n",
    "\n",
    "The algorithm aims to find the solution(s) with the highest fitness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1775d524",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "This *could* be a convex function, which would be nice because:\n",
    "- we wouldn't have to worry about getting stuck in local optima (convex functions are well-behaved because any local minimum is also a unique global minimum and there are many efficient algorithms for finding optimal solutions)\n",
    "- less sensitive to initialisation and parameter choices\n",
    "- reliable for a wide range of practical applications\n",
    "\n",
    "But we're rarely dealing with well-behaved convex functions and will often have multiple local optima or complex constraints\n",
    "\n",
    "Swarm optimisation is comparatively good at avoiding premature converge to local minima in multimodal problem optimisation and typically balance fast converge speed with an ability to jump out of local optima.\n",
    "\n",
    "<!-- Standard search space benchmarks\n",
    "- sphere\n",
    "- Rastrigin\n",
    "- Rosenbrock\n",
    "- Griewank -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c12d85",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Moving through the search space\n",
    "The agents move over the search space \n",
    "\n",
    "In PSO agents move through the search space with a velocity that is dynamically adjusted according to its own and its neighbours’ historical behaviour. In particular, movement is influenced by:\n",
    "- the best state this individual has found so far\n",
    "- the best state that its neighbours have found so far\n",
    "\n",
    "i.e. an agent 'learns' from itself and others\n",
    "\n",
    "In other swarm algorithms different combinations of the information shared and received are used, e.g.:\n",
    "- the local or global best solution (position) or some combination of multiple best solutions, e.g. BA, ABC, WSA\n",
    "- a subset or combination of all of better solutions, e.g. ABC, FFA\n",
    "- a combination of all solutions (centroid), e.g. AFSA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51293ea9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### Exploration and Exploitation\n",
    "\n",
    "Successful optimisation requires a balance between *exploration and exploitation* within the search space\n",
    "\n",
    "**exploration:** searching for new, potentially better solutions\n",
    "<!-- - 'inertia weight' on the agent velocity \n",
    "- incorporating stochasticity -->\n",
    "\n",
    "**exploitation:** focusing on known, promising solutions\n",
    "\n",
    "Generally speaking, algorithm should have a more exploration and less exploitation ability at first\n",
    "\n",
    "Exploration can then be be decreased, and exploitation increased to refine candidate solutions over the time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742aee7f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### Forces\n",
    "\n",
    "Velocity is a linear combination of personal inertia (exploration) and influences/biases (both personal and social), which act to enforce social norms and what has been good so far\n",
    "$$\n",
    "v_i(t+1)=wv_i(t) + p U_1 (x_{i_b}-x_i(t)) + s U_2(x_{g_b}-x_i(t))\n",
    "$$\n",
    "\n",
    "- inertia (first term) encourages particle to move in same direction depending on the strength of the inertia weight $w$ (possibly a function changing dynamically over time). $w$ can be used to control the balance between exploration and exploitation\n",
    "- personal bias (second term) aims for short-sighted improvement by directing the particle to return to a previous position best position, $x_{i_b}$\n",
    "- social bias (third term) aims for conformity by directing the particle to follow the best position found so far, $x_{g_b}$\n",
    "\n",
    "\n",
    "$p$, $s$, $U_1$ and $U_2$ are hyperparameters (parameter whose value is used to control the learning process) \n",
    "- $p$ and $s$ weigh the importance of the particle's personal previous experiences and those of the group respectively \n",
    "- $U_n$ are random values drawn from the range [0,1]. This is essential for avoiding premature convergences to local minima"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6bb3ae",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### Randomness\n",
    "\n",
    "We will often lean on stochasticity to:\n",
    "- handle uncertainty e.g. uncertain or noisy objective functions \n",
    "- encourage diversity among swarm agents and the set of solutions they explore by perturbing the state or drivers by random factors. This can help the swarm to avoid premature convergence (where the swarm settles too quickly on suboptimal solutions) and escape local optima by covering a larger portion of the solution space efficiently (helping to balance the trade-off of exploration vs exploitation)\n",
    "    - a lot of randomness allows exploration of new possibilities\n",
    "    - a bit of randomness allows exploitation by testing patterns similar to the best one found so far\n",
    "\n",
    "Can be introduced via:\n",
    "- random initialisation of particles' positions and velocities \n",
    "- probabilistic forces or decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba56162e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The picture to have in mind\n",
    "\n",
    "<center>\n",
    "<img src=\"ParticleSwarmArrowsAnimation.gif\" width=\"400\"/>\n",
    "</center>\n",
    "\n",
    "But the landscape may:\n",
    "- be complex, noisy, and high-dimensional \n",
    "- change over time\n",
    "- have multiple optimas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedb6258",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "Consider, for example, the problem of training a neural network for image classification:\n",
    "- The fitness function could be the accuracy of the neural network on a validation set, which measures how well the network is performing on unseen data\n",
    "- The solution space consists of all possible configurations of the neural network’s weights and biases. This space is typically high-dimensional and extremely complex."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b4f736",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## An* algorithm (pseudo-code)\n",
    "\n",
    "<center>\n",
    "<img src=\"PSO_Algorithm2.png\" width=\"400\"/>\n",
    "</center>\n",
    "\n",
    "$*$ Note that this is a slight variant with the social component based on a local network and the global best only stored and not influencing the dynamics directly \n",
    "\n",
    "Figure from PSO review article here: https://link.springer.com/article/10.1007/s40747-018-0071-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c28cff",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Limitations and considerations\n",
    "\n",
    "**Advantages**\n",
    "- simple implementation\n",
    "- not a lot of hyper-parameters and very flexible with the form of the objective function, so is able to solve a wide range of problems\n",
    "- relatively insensitive to scaling of design variables \n",
    "- easily parallelised for concurrent and efficient processing \n",
    "\n",
    "**Disadvantages**\n",
    "- final solution is heavily dependent on the initial seeds of the population (so ensemble runs are especially important)\n",
    "- can have a tendency to a fast and premature convergence to sub optimal points\n",
    "- convergence can be slow in the refined search stage (weak local search ability)\n",
    "\n",
    "<!-- Difficult because:\n",
    "- Complex group dynamics\n",
    "- Stochastic search algorithm\n",
    "- Performance depends on the search landscape -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9384d815",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Hyperparameters\n",
    "a hyperparameter is a parameter whose value is used to control the learning process.\n",
    "Given these hyperparameters, the training algorithm learns the parameters from the data. \n",
    "Most performance variation can be attributed to just a few hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f20a16",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Read the OG PSO paper - it's fantastic and full of gems like this...\n",
    "*\"This is a major distinction in terms of contriving a computer simulation,for at least one obvious reason: collision. Two individuals can hold identical attitudes and beliefs without banging together,but two birds cannot occupy the same position in space without colliding. It seems reasonable, in discussing human social behavior,to map the concept of change into the bird fish analogy of movement. This is consistent with the classic Aristotelian view of qualitative and quantitative change as types of movement. Thus, besides moving through three-dimensional physical space, and avoiding collisions, humans change in abstract multi-dimensional space, collision-free. Physical space of course affects informational inputs, but it is arguably a trivial component of psychological experience. Humans learn to avoid physical collision by an early age...\"* \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4de1617",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "What has it been used for?\n",
    "- scheduling problem\n",
    "- data mining"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
